{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b8a2686",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/03/05 10:45:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "     .master(\"local[*]\") \\\n",
    "     .appName(\"groupby_spark\") \\\n",
    "     .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71a76cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green = spark.read.parquet(\"data/pq/green/*/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29c1780a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiangivyli/spark/spark-3.3.2-bin-hadoop3/python/pyspark/sql/dataframe.py:229: FutureWarning: Deprecated in 2.0, use createOrReplaceTempView instead.\n",
      "  warnings.warn(\"Deprecated in 2.0, use createOrReplaceTempView instead.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df_green.registerTempTable(\"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec4ebbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_revenue = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    -- Reveneue grouping \n",
    "    PULocationID AS zone,\n",
    "    date_trunc(\"hour\", lpep_pickup_datetime) AS hour, \n",
    "\n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) AS number_records\n",
    "FROM \n",
    "    green\n",
    "WHERE\n",
    "    lpep_pickup_datetime >= \"2020-01-01 00:00:00\"\n",
    "GROUP BY \n",
    "    zone, hour\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c22d047a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green_revenue \\\n",
    "    .repartition(6) \\\n",
    "    .write \\\n",
    "    .parquet(\"data/report/revenue/green\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8282e0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 32:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+------------------+--------------+\n",
      "|zone|               hour|            amount|number_records|\n",
      "+----+-------------------+------------------+--------------+\n",
      "| 265|2020-01-07 08:00:00|             60.22|             2|\n",
      "| 218|2020-01-02 11:00:00|115.46000000000001|             4|\n",
      "|  74|2020-01-19 19:00:00| 749.4399999999996|            56|\n",
      "| 196|2020-01-09 11:00:00|148.79000000000002|             9|\n",
      "|  95|2020-01-04 12:00:00|224.34000000000012|            15|\n",
      "|  64|2020-01-12 10:00:00|             45.04|             2|\n",
      "|  11|2020-01-25 14:00:00|             55.51|             1|\n",
      "| 129|2020-01-21 15:00:00|            139.54|            11|\n",
      "|  52|2020-01-01 23:00:00|               6.3|             1|\n",
      "|  82|2020-01-30 05:00:00|152.35000000000002|             8|\n",
      "| 129|2020-01-15 22:00:00|272.95000000000005|            14|\n",
      "| 145|2020-01-25 10:00:00|             80.22|             7|\n",
      "| 260|2020-01-10 23:00:00| 248.9300000000001|            20|\n",
      "|  65|2020-01-22 11:00:00|            222.69|            14|\n",
      "|  95|2020-01-29 18:00:00| 475.4800000000002|            40|\n",
      "|   7|2020-01-22 17:00:00| 476.4700000000002|            34|\n",
      "|  74|2020-01-11 21:00:00| 936.7899999999993|            59|\n",
      "| 117|2020-01-31 06:00:00|            183.77|             3|\n",
      "|  66|2020-01-25 16:00:00|172.28000000000003|             9|\n",
      "|  82|2020-01-10 18:00:00| 839.0399999999995|            59|\n",
      "+----+-------------------+------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green_revenue = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "045bc2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow = spark.read.parquet(\"data/pq/yellow/*/*\")\n",
    "df_yellow.registerTempTable(\"yellow\")\n",
    "df_yellow_revenue = spark.sql(\"\"\"\n",
    "SELECT \n",
    "    -- Reveneue grouping \n",
    "    PULocationID AS zone,\n",
    "    date_trunc(\"hour\", tpep_pickup_datetime) AS hour, \n",
    "\n",
    "    SUM(total_amount) AS amount,\n",
    "    COUNT(1) AS number_records\n",
    "FROM \n",
    "    yellow\n",
    "WHERE\n",
    "    tpep_pickup_datetime >= \"2020-01-01 00:00:00\"\n",
    "GROUP BY \n",
    "    zone, hour\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00652409",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_yellow_revenue \\\n",
    "    .repartition(6) \\\n",
    "    .write \\\n",
    "    .parquet(\"data/report/revenue/yellow\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb5a0af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_green_revenue = spark.read.parquet(\"data/report/revenue/green\")\n",
    "df_yellow_revenue = spark.read.parquet(\"data/report/revenue/yellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66aaf7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_green_revenue_tmp = df_green_revenue \\\n",
    "    .withColumnRenamed(\"amount\", \"green_amount\") \\\n",
    "    .withColumnRenamed(\"number_records\", \"green_number_records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44865b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yellow_revenue_tmp = df_yellow_revenue \\\n",
    "    .withColumnRenamed(\"amount\", \"yellow_amount\") \\\n",
    "    .withColumnRenamed(\"number_records\", \"yellow_number_records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3168b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df_green_revenue_tmp \\\n",
    "    .join(df_yellow_revenue_tmp, on=[\"hour\", \"zone\"], how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8727a1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join.write.parquet(\"data/report/revenue/total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e35001f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+------------------+--------------------+------------------+---------------------+\n",
      "|               hour|zone|      green_amount|green_number_records|     yellow_amount|yellow_number_records|\n",
      "+-------------------+----+------------------+--------------------+------------------+---------------------+\n",
      "|2020-01-01 00:00:00|   3|              null|                null|              25.0|                    1|\n",
      "|2020-01-01 00:00:00|   4|              null|                null|1004.3000000000002|                   57|\n",
      "|2020-01-01 00:00:00|   7| 769.7299999999996|                  45| 455.1700000000001|                   38|\n",
      "|2020-01-01 00:00:00|  12|              null|                null|             107.0|                    6|\n",
      "|2020-01-01 00:00:00|  13|              null|                null|1214.8000000000002|                   56|\n",
      "|2020-01-01 00:00:00|  18|               7.8|                   1|               5.8|                    1|\n",
      "|2020-01-01 00:00:00|  29|              61.3|                   1|              null|                 null|\n",
      "|2020-01-01 00:00:00|  36|295.34000000000003|                  11|            109.17|                    3|\n",
      "|2020-01-01 00:00:00|  37|            175.67|                   6|161.60999999999999|                    7|\n",
      "|2020-01-01 00:00:00|  38| 98.78999999999999|                   2|              null|                 null|\n",
      "|2020-01-01 00:00:00|  40|168.97999999999996|                   8|             89.97|                    5|\n",
      "|2020-01-01 00:00:00|  41|1363.9599999999987|                  84|1256.5299999999997|                   80|\n",
      "|2020-01-01 00:00:00|  45|              null|                null| 732.4800000000002|                   42|\n",
      "|2020-01-01 00:00:00|  47|              13.3|                   1|               8.3|                    1|\n",
      "|2020-01-01 00:00:00|  48|              null|                null|10773.360000000022|                  455|\n",
      "|2020-01-01 00:00:00|  51|              17.8|                   2|              31.0|                    1|\n",
      "|2020-01-01 00:00:00|  60|            160.04|                   6|57.620000000000005|                    2|\n",
      "|2020-01-01 00:00:00|  61| 526.7099999999999|                  17|            146.64|                    3|\n",
      "|2020-01-01 00:00:00|  62|             15.95|                   1|             61.43|                    1|\n",
      "|2020-01-01 00:00:00|  63|              51.9|                   2|              70.8|                    1|\n",
      "+-------------------+----+------------------+--------------------+------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_join.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26c0ffa",
   "metadata": {},
   "source": [
    "merge zone name into one table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "893de4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = spark.read.parquet(\"data/zones/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40a11e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------------------+------------+\n",
      "|LocationID|      Borough|                Zone|service_zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "|         1|          EWR|      Newark Airport|         EWR|\n",
      "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
      "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
      "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
      "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
      "|         6|Staten Island|Arrochar/Fort Wad...|   Boro Zone|\n",
      "|         7|       Queens|             Astoria|   Boro Zone|\n",
      "|         8|       Queens|        Astoria Park|   Boro Zone|\n",
      "|         9|       Queens|          Auburndale|   Boro Zone|\n",
      "|        10|       Queens|        Baisley Park|   Boro Zone|\n",
      "|        11|     Brooklyn|          Bath Beach|   Boro Zone|\n",
      "|        12|    Manhattan|        Battery Park| Yellow Zone|\n",
      "|        13|    Manhattan|   Battery Park City| Yellow Zone|\n",
      "|        14|     Brooklyn|           Bay Ridge|   Boro Zone|\n",
      "|        15|       Queens|Bay Terrace/Fort ...|   Boro Zone|\n",
      "|        16|       Queens|             Bayside|   Boro Zone|\n",
      "|        17|     Brooklyn|             Bedford|   Boro Zone|\n",
      "|        18|        Bronx|        Bedford Park|   Boro Zone|\n",
      "|        19|       Queens|           Bellerose|   Boro Zone|\n",
      "|        20|        Bronx|             Belmont|   Boro Zone|\n",
      "+----------+-------------+--------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_zones.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21dff8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df_join.join(df_zones, df_join.zone == df_zones.LocationID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dace6356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_result.drop(\"LocationID\", \"zone\").write.parquet(\"data/tmp/revenue-zones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c734aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b1b117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
